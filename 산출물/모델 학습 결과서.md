# 2. 모델 학습 결과서

## 최종 모델 선정을 위한 평가지표와 그에 대한 설명

- **Precision, Recall, F1-score**: 클래스 불균형 문제를 고려해 Accuracy보다 더 유의미한 지표로 설정
- **ROC-AUC**: 전체적인 이진 분류 성능을 판단하기 위해 사용
- **Threshold Tuning**: Precision-Recall 간 trade-off를 조정하기 위해 임계값 조정 수행

### 성능 비교표

| 모델               | Accuracy | Precision | Recall  | F1 Score |
|--------------------|----------|-----------|---------|----------|
| Logistic Regression | 0.9709   | 0.2851    | 0.1897  | 0.2278   |
| KNN Neighbors       | 0.9494   | 0.1681    | 0.3126  | 0.2186   |
| Decision Tree       | 0.9662   | 0.3003    | 0.3722  | 0.3324   |
| Random Forest       | 0.9841   | 0.9883    | 0.3010  | 0.4614   |
| Gradient Boosting   | 0.9841   | 0.9911    | 0.2983  | 0.4586   |
| XGBoost             | 0.9831   | 0.8295    | 0.3206  | 0.4624   |

## 최종 선정된 모델에 대한 설명

- **선정 모델**: XGBoost
- **최종 하이퍼파라미터**
  ```json
  {
    "subsample": 1.0,
    "n_estimators": 200,
    "max_depth": 4,
    "learning_rate": 0.2,
    "gamma": 0,
    "colsample_bytree": 1.0
  }
  ```
- **성능 요약**:
  - Precision: 0.96
  - Recall: 0.31
  - F1 Score: 0.46
  - Threshold 최적값: **0.30**
  - F1 Score (Threshold 조정 후): **0.4807**

### Threshold별 F1 Score 변화

| Threshold | F1 Score | Precision | Recall  |
|-----------|----------|-----------|---------|
| 0.10      | 0.3706   | 0.2720    | 0.5813  |
| 0.15      | 0.4287   | 0.3760    | 0.4984  |
| 0.20      | 0.4593   | 0.4861    | 0.4354  |
| 0.25      | 0.4774   | 0.6045    | 0.3944  |
| 0.30      | **0.4807** | 0.7070  | 0.3642  |
| 0.35      | 0.4780   | 0.7929    | 0.3421  |
| 0.40      | 0.4734   | 0.8736    | 0.3247  |
| 0.45      | 0.4674   | 0.9262    | 0.3126  |
| 0.50      | 0.4627   | 0.9575    | 0.3051  |

## 학습 과정 기록

- 데이터셋이 매우 큰 관계로 test set 비율을 점차 증가시키며 실험
- 최종적으로 train:test = 7:3 비율에서 가장 균형 잡힌 성능 확인
- SMOTE 적용은 train set에만 적용하고, test set은 원본 데이터 그대로 사용하여 평가 신뢰도 확보
- XGBoost 모델 저장 및 threshold 값 저장 후 추론 시 함께 불러오는 방식 적용
